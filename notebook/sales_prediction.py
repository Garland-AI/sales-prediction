# -*- coding: utf-8 -*-
"""sales-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17NI8vfmCY8FxdJXvAy_qDd_HzHAEraKt
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f

from google.colab import drive
drive.mount('/content/drive')

##read excel
import pandas as pd
data_path = "/content/drive/MyDrive/sales-prediction/sales.xlsx"
df= pd.read_excel(data_path, engine='openpyxl')

df.info()

## filter data

# Convert 'Delivery Date' to datetime
df['Delivery Date'] = pd.to_datetime(df['Delivery Date'], errors='coerce')

df = df.dropna(subset=['Delivery Date'])

# Extract the month and year from 'Delivery Date'
df['YearMonth'] = df['Delivery Date'].dt.to_period('M')

df['Unit Price'] = df['Total Sales'] / df['Quantity']

# Remove trailing whitespace from 'Item Description'
df['Item Description'] = df['Item Description'].str.strip()

df['Customer ID'] = df['Customer ID'].str.strip()

# Extracting unique item codes and descriptions
item_dict = df.drop_duplicates(subset=['Itemcode']).set_index('Itemcode')['Item Description'].to_dict()

# Extracting unique item codes and unit prices
unit_price_dict = df.drop_duplicates(subset=['Itemcode']).set_index('Itemcode')['Unit Price'].to_dict()

# Assuming your DataFrame is named df

# Group by 'YearMonth' and 'Itemcode'
grouped = df.groupby(['YearMonth', 'Itemcode' , 'Customer ID']).agg({
    'Total Sales': 'sum',
}).reset_index()

# Sort the result by 'YearMonth' and 'Itemcode'
grouped = grouped.sort_values(by=['YearMonth', 'Customer ID' ,  'Itemcode'])

# Define the current month
current_month = pd.Period.now('M')

# Filter out the data for the current month
grouped= grouped[grouped['YearMonth'] != current_month]

grouped = grouped[grouped['Customer ID'] != '']

grouped
#810006 is 378269.10 in last

import numpy as np


last_period = grouped['YearMonth'].max()

filtered_study = grouped[grouped['YearMonth'] == last_period]


study_items = np.sort(filtered_study['Itemcode'].unique())
study_customers = np.sort(filtered_study['Customer ID'].unique())

grouped = grouped[grouped['Itemcode'].isin(study_items) & grouped['Customer ID'].isin(study_customers)]
# Get all unique periods and item codes

study_periods = grouped['YearMonth'].unique()


# Create a DataFrame with all combinations of periods and item codes
all_combinations = pd.MultiIndex.from_product([study_periods, study_items , study_customers], names=['YearMonth', 'Itemcode' , 'Customer ID']).to_frame(index=False)

# Merge with grouped data, filling missing values with 0 for Quantity and Total Sales
complete_data = pd.merge(all_combinations, grouped, on=['YearMonth', 'Itemcode' , 'Customer ID'], how='left').fillna({'Total Sales': 0})



complete_data = complete_data.sort_values(by=['YearMonth', 'Customer ID' ,  'Itemcode'])

complete_data

import matplotlib.pyplot as plt

# Group the data by 'YearMonth' and sum the 'Total Sales'
monthly_sales = grouped.groupby('YearMonth')['Total Sales'].sum().reset_index()

# Plotting the data
plt.figure(figsize=(8, 5))
plt.plot(monthly_sales['YearMonth'].astype(str), monthly_sales['Total Sales'], marker='o')

plt.title('Total Sales Per Month')
plt.xlabel('Month')
plt.ylabel('Total Sales')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()

# Prepare the DataFrame for the specific item IDs
study_data = complete_data[complete_data['Itemcode'].isin(study_items) & complete_data['Customer ID'].isin(study_customers)]
# Pivot the data to get sales for each item in separate columns


# Pivot the DataFrame
pivoted_df = study_data.pivot_table(index=['YearMonth', 'Customer ID'], columns='Itemcode', values='Total Sales').reset_index()


pivoted_df = pivoted_df.sort_values(by=['YearMonth', 'Customer ID']).drop(columns=["YearMonth" , "Customer ID"])

pivoted_df

from sklearn.preprocessing import MinMaxScaler


def prepare_data(data , n):
    result = []
    for index in range(0, len(data), n):
        result.append(data[index: index + n])
    return np.array(result)


# Function to create sequences for time series data
def create_sequences(data, time_steps):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:(i + time_steps)])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)



# Create sequences
# Scale the data



prepared_data = prepare_data(pivoted_df.values , len(study_customers))



# Define the number of time steps
time_steps = len(prepared_data)//10

X, y = create_sequences(prepared_data, time_steps)

print(X.shape)
print(y.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout , Flatten, Reshape, TimeDistributed



# Reshape the input data
X_reshaped = X.reshape(X.shape[0], X.shape[1], -1)

# Define the input shape
input_shape = (X_reshaped.shape[1], X_reshaped.shape[2])

# Total size for reshaping should be 475 * 120
total_size =y.shape[1] * y.shape[2]

# Build the model
model = Sequential()
model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=input_shape))
model.add(LSTM(50, activation='relu', return_sequences=False))
model.add(Dense(total_size, activation='relu'))  # Adjust the Dense layer output size
model.add(Reshape((y.shape[1] , y.shape[2])))  # Ensure the reshape matches the total size

# Compile the model
model.compile(optimizer='adam', loss='mse')


# Assuming you have your reshaped X and y prepared
# X_reshaped.shape should be (30, 3, 57000)
# y.shape should be (30, 475, 120)


# Train the model quietly
model.fit(X_reshaped, y, epochs=100, batch_size=64)

y_pred = model.predict(X_reshaped)





item_id = 110020  # 'Itemcode' for the item you want to predict
customer_id = 'COSTCO-CSC280'  # 'Customer ID' for the customer you want to predict

item_index = np.where(study_items == item_id)[0][0]
customer_index = np.where(study_customers == customer_id)[0][0]




predicted_data = y_pred[:,customer_index ,  item_index ]
true_data = y[:,customer_index ,  item_index ]

plot_index = study_periods.astype(str)


# Plot real vs. predicted quantity
plt.figure(figsize=(12, 6))
plt.plot(plot_index[time_steps:], true_data, label='Actual Sales')
plt.plot(plot_index[time_steps:], predicted_data, label='Predicted Sales', linestyle='--')
plt.title(f'Sales for Item: {item_dict[item_id]}, Customer: {customer_id}')
plt.xlabel('YearMonth')
plt.ylabel('Total Sales')
plt.legend()
plt.xticks(rotation=90)
# Add last prediction value as text annotation
last_pred_value = predicted_data[-1]
plt.text(plot_index[-1], last_pred_value, f'{last_pred_value:.2f}', color='red')
plt.show()



last_X = prepared_data[-time_steps:].reshape(1, time_steps, -1)

last_prediction = model.predict(last_X).reshape(y.shape[1] , y.shape[2])

last_real = y[-1].reshape(y.shape[1] , y.shape[2])

last_train = y_pred[-1].reshape(y.shape[1] , y.shape[2])

last_prediction_df = pd.DataFrame(last_prediction, index=study_customers, columns=study_items).reset_index().melt(id_vars='index', var_name='Item ID', value_name='Predicted Total Sales October').rename(columns={'index': 'Customer ID'})

last_train_df = pd.DataFrame(last_train, index=study_customers, columns=study_items).reset_index().melt(id_vars='index', var_name='Item ID', value_name='Predicted Total Sales September').rename(columns={'index': 'Customer ID'})

# Assuming last_real and last_prediction have the same shape
last_real_df = pd.DataFrame(last_real, index=study_customers, columns=study_items).reset_index().melt(id_vars='index', var_name='Item ID', value_name='Real Sales September').rename(columns={'index': 'Customer ID'})


merged_df = pd.merge(last_prediction_df, last_real_df , on=['Customer ID', 'Item ID'], how='left')


merged_df =  pd.merge(merged_df, last_train_df , on=['Customer ID', 'Item ID'], how='left')




merged_df = merged_df[(merged_df['Predicted Total Sales October'] > 0 ) & (merged_df['Predicted Total Sales September'] > 0)]


# Map the unit prices from the dictionary to a new column
merged_df['Unit Price'] = merged_df['Item ID'].map(unit_price_dict)

# Calculate the quantity
merged_df['Predicted Quantity October'] = merged_df['Predicted Total Sales October'] / merged_df['Unit Price']

merged_df['Real Quantity September'] = merged_df['Real Sales September'] / merged_df['Unit Price']

merged_df['Predicted Quantity September'] = merged_df['Predicted Total Sales September'] / merged_df['Unit Price']

merged_df = merged_df.drop(columns=['Unit Price'])[['Customer ID', 'Item ID','Real Quantity September', 'Real Sales September' , 'Predicted Quantity September' , 'Predicted Total Sales September','Predicted Quantity October', 'Predicted Total Sales October'] ]



merged_df.to_excel('sales-predictions-v1.1.xlsx', index=False)
merged_df

